<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Girish Varma</title>
    <link>https://girishvarma.in/</link>
    <description>Recent content on Girish Varma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Nov 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://girishvarma.in/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/about/</guid>
      <description>Hi! I am an Asst. Prof. at the Center for Security, Theory &amp;amp; Algorithms Research (CSTAR) and the Machine Learning Lab at IIIT Hyderabad. I am broadly interested in theoretical and applied computer science problems.
I did my Phd thesis on Computational Complexity theory (at TIFR Mumbai) and continues to have interest in Complexity theory, Combinatorics and Graph theory. Later I went on to do research (at IIIT Hyderabad) in Deep Learning, specifically Model Compression techniques and Semantic Segmentation for Autonomous Navigation.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/teaching/</guid>
      <description> Teaching  AI/ML for Natural Sciences, Jan 2019
 Foundations of Artificial Intelligence and Machine Learning
 Efficient CNNs (Reading Group), Jan 2018
 Multi Object Tracking using Deep Learning (Reading Group), Jan 2018
 Computational Complexity Theory, Sept - Nov 2017
    </description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/events/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/events/</guid>
      <description>Events &amp;amp; Talks  Scene Understanding Challenge for Auto. Nav. in Unstructured Environments
Second International Workshop On Auto. Nav. in Unconstrained Environments 
in Conjunction with ICCV 2019, November 2, 2019, Seoul.
 Semantic Segmentation: Recent Advances, Indian Datasets &amp; Universal Segmentation Problems Challenges and Advances in Vision-Based Self-Driving
Tutorial cohosted with Prof. Manmohan Chandrakar (UCSD) at ICVGIP&#39;18, Hyderabad. December, 2018
 IDD Dataset and Challenge ICTAI Workshop on Unstructured Driving Scenarios in India</description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/projects/</guid>
      <description> Research Areas </description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/home/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/home/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Universal Semi-supervised Semantic Segmentation</title>
      <link>https://girishvarma.in/publication/univ-seg/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/univ-seg/</guid>
      <description>In recent years, the need for semantic segmentation has arisen across several different applications and environments. However, the expense and redundancy of annotation often limits the quantity of labels available for training in any domain, while deployment is easier if a single model works well across domains. In this paper, we pose the novel problem of universal semi-supervised semantic segmentation and propose a solution framework, to meet the dual needs of lower annotation and deployment costs.</description>
    </item>
    
    <item>
      <title>IDD: A Dataset for exploring problems in Autonomous Navigation in Unconstrained Environments</title>
      <link>https://girishvarma.in/publication/idd/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/idd/</guid>
      <description>While several datasets for autonomous navigation have become available in recent years, they tend to focus on structured driving environments. This usually corresponds to well-delineated infrastructure such as lanes, a small number of well-defined categories for traffic participants, low variation in object or background appearance and strict adherence to traffic rules. We propose IDD, a novel dataset for road scene understanding in unstructured environments where the above assumptions are largely not satisfied.</description>
    </item>
    
    <item>
      <title>Deep Expander Networks: Efficient Deep Networks from Graph Theory</title>
      <link>https://girishvarma.in/publication/xnet/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/xnet/</guid>
      <description>Efficient CNN designs like ResNets and DenseNet were proposed to improve accuracy vs efficiency trade-offs. They essentially increased the connectivity, allowing efficient information flow across layers. Inspired by these techniques, we propose to model connections between filters of a CNN using graphs which are simultaneously sparse and well connected. Sparsity results in efficiency while well connectedness can preserve the expressive power of the CNNs. We use a well-studied class of graphs from theoretical computer science that satisfies these properties known as Expander graphs.</description>
    </item>
    
    <item>
      <title>Improved Visual Relocalization by Discovering Anchor Points</title>
      <link>https://girishvarma.in/publication/visual-reloc-achor/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/visual-reloc-achor/</guid>
      <description>We address the visual relocalization problem of predicting the location and camera orientation or pose (6DOF) of the given input scene. We propose a method based on how humans determine their location using the visible landmarks. We define anchor points uniformly across the route map and propose a deep learning architecture which predicts the most relevant anchor point present in the scene as well as the relative offsets with respect to it.</description>
    </item>
    
    <item>
      <title>Cityscale Road Audit System using Deep Learning</title>
      <link>https://girishvarma.in/publication/road-audit/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/road-audit/</guid>
      <description>Road networks in cities are massive and is a critical component of mobility. Fast response to defects, that can occur not only due to regular wear and tear but also because of extreme events like storms, is essential. Hence there is a need for an automated system that is quick, scalable and cost-effective for gathering information about defects. We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation.</description>
    </item>
    
    <item>
      <title>Efficient Semantic Segmentation using Gradual Grouping</title>
      <link>https://girishvarma.in/publication/grad-group/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/grad-group/</guid>
      <description>Deep CNNs for semantic segmentation have high memory and run time requirements. Various approaches have been proposed to make CNNs efficient like grouped, shuffled, depth-wise separable convolutions. We study the effectiveness of these techniques on a real-time semantic segmentation architecture like ERFNet for improving runtime by over 5X. We apply these techniques to CNN layers partially or fully and evaluate the testing accuracies on Cityscapes dataset. We obtain accuracy vs parameters/FLOPs trade offs, giving accuracy scores for models that can run under specified runtime budgets.</description>
    </item>
    
    <item>
      <title>Class2Str: End to End Latent Hierarchy Learning</title>
      <link>https://girishvarma.in/publication/class2str/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/class2str/</guid>
      <description>Deep neural networks for image classification typically consists of a convolutional feature extractor followed by a fully connected classifier network. The predicted and the ground truth labels are represented as one hot vectors. Such a representation assumes that all classes are equally dissimilar. However, classes have visual similarities and often form a hierarchy. Learning this latent hierarchy explicitly in the architecture could provide invaluable insights. We propose an alternate architecture to the classifier network called the Latent Hierarchy (LH) Classifier and an end to end learned Class2Str mapping which discovers a latent hierarchy of the classes.</description>
    </item>
    
    <item>
      <title>Efficient CNNs</title>
      <link>https://girishvarma.in/teaching/efficient-cnns/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/efficient-cnns/</guid>
      <description>Surveying Deep learning methods used in Reinforcement Learning</description>
    </item>
    
    <item>
      <title>Multi Object Tracking using Deep Learning</title>
      <link>https://girishvarma.in/teaching/mot/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/mot/</guid>
      <description>Surveying Deep learning methods used in Reinforcement Learning</description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/complexity-notes/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/complexity-notes/</guid>
      <description>MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; }, extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;, &#34;autobold.js&#34;, &#34;color.js&#34;] } });   A Short Course on Complexity Theory  Nov 11, 2017 Table of contents  Lecture 1: Introduction 
&amp;nbsp; &amp;nbsp; &amp;nbsp; Decision Problems 
&amp;nbsp; &amp;nbsp; &amp;nbsp; Turing Machines 
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Robustness of TM 
&amp;nbsp; &amp;nbsp; &amp;nbsp; Efficient Algorithms 
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; Polynomial time vs Exponential Time</description>
    </item>
    
    <item>
      <title>Complexity Theory</title>
      <link>https://girishvarma.in/teaching/complexity-theory/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/complexity-theory/</guid>
      <description>Surveying Deep learning methods used in Reinforcement Learning</description>
    </item>
    
    <item>
      <title>Compressing Models for Recognizing Places</title>
      <link>https://girishvarma.in/publication/compression-place/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/compression-place/</guid>
      <description>Visual place recognition on low memory devices such as mobile phones and robotics systems is a challenging problem. The state of the art models for this task uses deep learning architectures having close to 100 million parameters which takes over 400MB of memory. This makes these models infeasible to be deployed in low memory devices and gives rise to the need of compressing them. Hence we study the effectiveness of model compression techniques like trained quantization and pruning for reducing the number of parameters on one of the best performing image retrieval models called NetVLAD.</description>
    </item>
    
    <item>
      <title>Hardness of Approximate Coloring</title>
      <link>https://girishvarma.in/publication/thesis/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/thesis/</guid>
      <description>The graph coloring problem is a notoriously hard problem, for which we do not have efficient algorithms. A coloring of a graph is an assignment of colors to its vertices such that the end points of every edge have different colors. A k-coloring is a coloring that uses at most k distinct colors. The graph coloring problem is to find a coloring that uses the minimum number of colors. Given a 3-colorable graph, the best known efficient algorithms output an n0.</description>
    </item>
    
    <item>
      <title>A Characterization of Hard-to-cover CSPs</title>
      <link>https://girishvarma.in/publication/characterization-covering/</link>
      <pubDate>Thu, 10 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/characterization-covering/</guid>
      <description>We continue the study of covering complexity of constraint satisfaction problems (CSPs) initiated by Guruswami, Hastad and Sudan [SIAM J. Computing, 31(6):1663&amp;ndash;1686, 2002] and Dinur and Kol [In Proc. 28th IEEE Conference on Computational Complexity, 2013]. The covering number of a CSP instance $\phi$, denoted by ν(Φ) is the smallest number of assignments to the variables of $\phi$, such that each constraint of Φ is satisfied by at least one of the assignments.</description>
    </item>
    
    <item>
      <title>Super-polylogarithmic hypergraph coloring hardness via low-degree long codes</title>
      <link>https://girishvarma.in/publication/hyper-coloring-journal/</link>
      <pubDate>Tue, 22 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/hyper-coloring-journal/</guid>
      <description>We prove improved inapproximability results for hypergraph coloring using the low-degree polynomial code (aka, the &amp;lsquo;short code&amp;rsquo; of Barak et. al. [FOCS 2012]) and the techniques proposed by Dinur and Guruswami [FOCS 2013] to incorporate this code for inapproximability results. In particular, we prove quasi-NP-hardness of the following problems on $n$-vertex hyper-graphs:
 Coloring a 2-colorable 8-uniform hypergraph with $2^{2^{\Omega(loglog\sqrt{n})}}$ colors. Coloring a 4-colorable 4-uniform hypergraph with $2^{2^{\Omega(loglog\sqrt{n})}}$ colors. Coloring a 3-colorable 3-uniform hypergraph with $(log n)^{\Omega(1/logloglog n)}$ colors.</description>
    </item>
    
    <item>
      <title>On Fortification of Projection Games</title>
      <link>https://girishvarma.in/publication/fortification/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/fortification/</guid>
      <description>A recent result of Moshkovitz cite{Moshkovitz14} presented an ingenious method to provide a completely elementary proof of the Parallel Repetition Theorem for certain projection games via a construction called fortification. However, the construction used in cite{Moshkovitz14} to fortify arbitrary label cover instances using an arbitrary extractor is insufficient to prove parallel repetition. In this paper, we provide a fix by using a stronger graph that we call fortifiers. Fortifiers are graphs that have both 1 and 2 guarantees on induced distributions from large subsets.</description>
    </item>
    
    <item>
      <title>Reducing uniformity in Khot-Saket hypergraph coloring hardness reductions</title>
      <link>https://girishvarma.in/publication/improved-khot-saket/</link>
      <pubDate>Sun, 10 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/improved-khot-saket/</guid>
      <description>In a recent result, Khot and Saket [FOCS 2014] proved the quasi-NP-hardness of coloring a 2-colorable 12-uniform hypergraph with 2(logn)Ω(1) colors. This result was proved using a novel outer PCP verifier which had a strong soundness guarantee. In this note, we show that we can reduce the arity of their result by modifying their 12-query inner verifier to an 8-query inner verifier based on the hypergraph coloring hardness reductions of Guruswami et.</description>
    </item>
    
    <item>
      <title>Derandomized Graph Product Results using the Low Degree Long Code</title>
      <link>https://girishvarma.in/publication/graph-prods/</link>
      <pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/graph-prods/</guid>
      <description>In this paper, we address the question of whether the recent derandomization results obtained by the use of the low-degree long code can be extended to other product settings. We consider two settings: (1) the graph product results of Alon, Dinur, Friedgut and Sudakov [GAFA, 2004] and (2) the \&amp;ldquo;majority is stablest\&amp;rdquo; type of result obtained by Dinur, Mossel and Regev [SICOMP, 2009] and Dinur and Shinkar [In Proc. APPROX, 2010] while studying the hardness of approximate graph coloring.</description>
    </item>
    
    <item>
      <title>Playing games in an uncertain world</title>
      <link>https://girishvarma.in/publication/playing-games/</link>
      <pubDate>Mon, 10 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/playing-games/</guid>
      <description>Traditional game theory assumes that the players in the game are aware of the rules of the game. However, in practice, often the players are unaware or have only partial knowledge about the game they are playing. They may also have knowledge that other players have only partial knowledge of the game they are playing, which they can try to exploit. We present a novel mathematical formulation of such games. We make use of Kripke semantics, which are a way to keep track of what different players know and do not know about the world.</description>
    </item>
    
    <item>
      <title> Physarum Can Compute Shortest Paths</title>
      <link>https://girishvarma.in/publication/slime-mold2/</link>
      <pubDate>Wed, 12 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/slime-mold2/</guid>
      <description>Physarum polycephalum is a slime mold that is apparently able to solve shortest path problems. A mathematical model has been proposed by Tero et al. (Journal of Theoretical Biology, 244, 2007, pp. 553–564) to describe the feedback mechanism used by the slime mold to adapt its tubular channels while foraging two food sources s0 and s1. We prove that, under this model, the mass of the mold will eventually converge to the shortest path of the network that the mold lies on, independently of the structure of the network or of the initial mass distribution.</description>
    </item>
    
    <item>
      <title>Streaming Algorithms for Language Recognition Problems</title>
      <link>https://girishvarma.in/publication/streaming2/</link>
      <pubDate>Tue, 05 Apr 2011 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/streaming2/</guid>
      <description>We study the complexity of the following problems in the streaming model. Membership testing for DLIN We show that every language in DLIN can be recognised by a randomized one-pass O(logn) space algorithm with inverse polynomial one-sided error, and by a deterministic p-pass O(n/p) space algorithm. We show that these algorithms are optimal.Membership testing for LL(k). For languages generated by LL(k) grammars with a bound of r on the number of nonterminals at any stage in the left-most derivation, we show that membership can be tested by a randomized one-pass O(rlogn) space algorithm with inverse polynomial (in n) one-sided error.</description>
    </item>
    
    <item>
      <title>Conductance and eigenvalue</title>
      <link>https://girishvarma.in/publication/conductance/</link>
      <pubDate>Wed, 10 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/conductance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research Opportunities</title>
      <link>https://girishvarma.in/openings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/openings/</guid>
      <description>I am looking for research students to work with me. The student can choose to do research on one of the following three paths.
 Purely Theoretical:  Research topics: Hardness of Approximation and PCPs, Property Testing, Streaming Algorithms (or Big Data algorithms in general), Computational Learning Theory. Qualifications: The student is expected to have done very well in algorithms, datastructures, basic math courses.   
 Theory + Applied:  Research Topics: Interpretable/Explanable AI, Graph/Information theoretic approaches to analysing Neural Networks or Big Data in general.</description>
    </item>
    
  </channel>
</rss>